{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3335ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Check for GPU\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✅ GPU Detected: {gpus}\")\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected. Training will run on CPU (slower).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4818bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Data\n",
    "# Make sure the CSV file is in the same directory as this notebook\n",
    "csv_path = 'SQLInjection_XSS_MixDataset.1.0.0.csv'\n",
    "\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"✅ Loaded dataset with {len(df)} rows\")\n",
    "else:\n",
    "    print(f\"❌ File not found: {csv_path}\")\n",
    "    print(\"Please download the dataset and place it in this folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing Functions\n",
    "def remove_comment(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r'//.*?\n",
    "|/\\*.*?\\*/', '', text, flags=re.S)\n",
    "    text = text.split('--')[0]+\"--\"\n",
    "    if '\\'' in text:\n",
    "        removeTarget = text.split('\\'')[0]\n",
    "        text = text.replace(removeTarget, \"\")\n",
    "    return text\n",
    "\n",
    "def data2char_index(X, max_len, is_remove_comment=False):\n",
    "    alphabet = \" abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "    result = [] \n",
    "    for data in X:\n",
    "        mat = []\n",
    "        if is_remove_comment:\n",
    "            data = remove_comment(data)\n",
    "        for ch in str(data):\n",
    "            ch = ch.lower()\n",
    "            if ch not in alphabet:\n",
    "                continue\n",
    "            mat.append(alphabet.index(ch))\n",
    "        result.append(mat)\n",
    "    return pad_sequences(np.array(result, dtype=object), padding='post', truncating='post', maxlen=max_len)\n",
    "\n",
    "def data_to_symbol_tag(X, max_len, is_remove_comment=False):\n",
    "    symbol = \" -,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "    result = [] \n",
    "    for data in X:\n",
    "        mat = []\n",
    "        if is_remove_comment:\n",
    "            data = remove_comment(data)\n",
    "        for ch in str(data):\n",
    "            ch = ch.lower()\n",
    "            if ch not in symbol:\n",
    "                mat.append(0)\n",
    "            else:\n",
    "                mat.append(symbol.index(ch))\n",
    "        result.append(mat)\n",
    "    return pad_sequences(np.array(result, dtype=object), padding='post', truncating='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data\n",
    "if 'df' in locals():\n",
    "    data = df['Sentence'].values\n",
    "    # Create labels\n",
    "    SQLInjection_label = df['SQLInjection'].values\n",
    "    XSS = df['XSS'].values\n",
    "    Normal = df['Normal'].values\n",
    "    label = np.array([SQLInjection_label, XSS, Normal]).T\n",
    "\n",
    "    # Split Data\n",
    "    trainX, testX, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "    trainX, x_val, y_train, y_val = train_test_split(trainX, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"Processing text data... (this may take a moment)\")\n",
    "    MAX_LEN = 1000\n",
    "    \n",
    "    trainX_text = data2char_index(trainX, max_len=MAX_LEN)\n",
    "    trainX_symbol = data_to_symbol_tag(trainX, max_len=MAX_LEN)\n",
    "    \n",
    "    x_val_text = data2char_index(x_val, max_len=MAX_LEN)\n",
    "    x_val_symbol = data_to_symbol_tag(x_val, max_len=MAX_LEN)\n",
    "    \n",
    "    testX_text = data2char_index(testX, max_len=MAX_LEN)\n",
    "    testX_symbol = data_to_symbol_tag(testX, max_len=MAX_LEN)\n",
    "    \n",
    "    print(\"Data processing complete.\")\n",
    "    print(f\"Train shape: {trainX_text.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c703b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model (Updated for Keras 3)\n",
    "def create_model(max_len):\n",
    "    pool_siz = 10\n",
    "    num_heads = 3\n",
    "    \n",
    "    # Text Input\n",
    "    input_text = tf.keras.layers.Input(shape=(max_len,), name=\"text_input\")\n",
    "    embed1 = tf.keras.layers.Embedding(input_dim=70, output_dim=105, input_length=max_len, trainable=False)(input_text)\n",
    "    cnn1 = tf.keras.layers.Conv1D(32, 3, padding='same', strides=1, activation='relu')(embed1)\n",
    "    cnn1 = tf.keras.layers.MaxPooling1D(pool_size=pool_siz)(cnn1)\n",
    "    \n",
    "    # GRU 1 (Bidirectional)\n",
    "    # In Keras 3, we can use go_backwards=True safely during training\n",
    "    GRU0 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, go_backwards=True))(cnn1)\n",
    "    \n",
    "    # Symbol Input\n",
    "    input_symbol = tf.keras.layers.Input(shape=(max_len,), name=\"symbol_input\")\n",
    "    embed2 = tf.keras.layers.Embedding(input_dim=34, output_dim=51, input_length=max_len, trainable=False)(input_symbol)\n",
    "    cnn1s = tf.keras.layers.Conv1D(32, 3, padding='same', strides=1, activation='relu')(embed2)\n",
    "    cnn1s = tf.keras.layers.MaxPooling1D(pool_size=pool_siz)(cnn1s)\n",
    "    \n",
    "    # GRU 2 (Bidirectional)\n",
    "    GRU0s = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True, go_backwards=True))(cnn1s)\n",
    "    \n",
    "    # Cross Attention\n",
    "    CrossAT1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=1)(GRU0, GRU0s)\n",
    "    \n",
    "    # Combine\n",
    "    combined = tf.keras.layers.add([GRU0 + CrossAT1, GRU0s + CrossAT1])\n",
    "    flat = tf.keras.layers.Flatten()(combined)\n",
    "    dnn1 = tf.keras.layers.Dense(3, activation=\"softmax\")(flat)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_text, input_symbol], outputs=dnn1)\n",
    "    return model\n",
    "\n",
    "model = create_model(1000)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "if 'trainX_text' in locals():\n",
    "    history = model.fit(\n",
    "        [trainX_text, trainX_symbol], \n",
    "        y_train, \n",
    "        batch_size=64, \n",
    "        epochs=10, \n",
    "        validation_data=([x_val_text, x_val_symbol], y_val)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc033f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model in NEW Format (.keras)\n",
    "model.save('sqli_xss_model_latest.keras')\n",
    "print(\"✅ Model saved as 'sqli_xss_model_latest.keras'\")\n",
    "\n",
    "# Also save weights just in case\n",
    "model.save_weights('sqli_xss_weights_latest.weights.h5')\n",
    "print(\"✅ Weights saved as 'sqli_xss_weights_latest.weights.h5'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
